# -*- coding: utf-8 -*-
"""data_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mr10U2s3Tn1FKC3r_3iLNhh3wxxyiOiz
"""

# Twitter Engagement Analysis

import os
import json
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.regression.mixed_linear_model import MixedLM

# file upload
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    BASE_DIR = '/content/drive/MyDrive'
except ImportError:
    BASE_DIR = '.'

search_dirs = [BASE_DIR, '/content', '/mnt/data', '.']
dataset_path = None
output_path = None
for d in search_dirs:
    ds = os.path.join(d, 'dataset.json')
    out = os.path.join(d, 'output.json')
    if dataset_path is None and os.path.exists(ds):
        dataset_path = ds
    if output_path is None and os.path.exists(out):
        output_path = out
    if dataset_path and output_path:
        break
if not (dataset_path and output_path):
    raise FileNotFoundError(f"Could not find dataset.json/output.json in {search_dirs}")

print(f"Using dataset: {dataset_path}\nUsing output:  {output_path}")

#json loader
def load_json(path):
    text = open(path, encoding='utf-8').read()
    text = re.sub(r',\s*([\]\}])', r'\1', text)
    try:
        obj = json.loads(text)
        if isinstance(obj, list):
            return obj
        if isinstance(obj, dict):
            for v in obj.values():
                if isinstance(v, list):
                    return v
            return [obj]
    except:
        pass
    records = []
    for line in text.splitlines():
        entry = line.strip().rstrip(',')
        if entry.startswith('{'):
            try:
                records.append(json.loads(entry))
            except:
                pass
    return records

#load and merge datasets
raw_data = pd.DataFrame(load_json(dataset_path))
sent_data = pd.DataFrame(load_json(output_path))
df = pd.merge(raw_data, sent_data, left_on='Text', right_on='text', how='inner')
print(f"Merged dataframe with {len(df)} tweets")

#preprocessing

for col in ['Replies', 'Reposts', 'Likes']:
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

df['engagement'] = df[['Replies', 'Reposts', 'Likes']].sum(axis=1)

df['Time'] = pd.to_datetime(df['Time'], errors='coerce')
df['year_month'] = df['Time'].dt.to_period('M').dt.to_timestamp()

if 'confidence_scores' in df.columns:
    df['sentiment_score'] = df['confidence_scores'].apply(lambda x: x.get('positive',0) - x.get('negative',0))
else:
    df['sentiment_score'] = 0.0

#content category flags
flags = {
    'has_image':      r'https?://\S+\.(jpg|png|gif)',
    'has_video':      r'https?://\S+\.(mp4|gif)',
    'policy':         r'health care|economy|education|tax|immigration|environment|infrastructure',
    'attack':         r'my opponent|they|crooked|failure|incompetent|radical',
    'encourage_vote': r'vote|voting|election|ballot|turn out|polls|polling'
}
for name, pat in flags.items():
    df[name] = df['Text'].str.contains(pat, flags=re.IGNORECASE, na=False)

# feature engineering
# log-transform engagement
df['log_engagement'] = np.log1p(df['engagement'])
#structural
df['tweet_length'] = df['Text'].str.len()
df['num_hashtags'] = df['Text'].str.count(r'#\w+')
df['num_mentions'] = df['Text'].str.count(r'@\w+')
df['hour_of_day'] = df['Time'].dt.hour

df['content_cat'] = df.apply(
    lambda row: '|'.join([k for k in flags if row[k]]) or 'none', axis=1
).astype('category')

#fit statistical models
ols_mod = smf.ols(
    'log_engagement ~ sentiment_score + C(content_cat) + tweet_length + num_hashtags + num_mentions + hour_of_day',
    data=df
).fit()
pois_mod = smf.glm(
    'engagement ~ sentiment_score + C(content_cat) + tweet_length + num_hashtags + num_mentions + hour_of_day',
    data=df,
    family=sm.families.NegativeBinomial()
).fit()
mixed_mod = MixedLM.from_formula(
    'log_engagement ~ sentiment_score + C(content_cat) + tweet_length + num_hashtags + num_mentions + hour_of_day',
    groups='politician', data=df
).fit(reml=False)
print("Models fitted successfully")

# label mappings
readable_cat = {
    'none': 'No Special Content',
    'has_image': 'Contains Image',
    'has_video': 'Contains Video',
    'policy': 'Policy Discussion',
    'attack': 'Attack Opponent',
    'encourage_vote': 'Encourage Voting',
    'has_image|policy': 'Image & Policy',
    'has_image|encourage_vote': 'Image & Encourage Voting',
    'policy|encourage_vote': 'Policy & Encourage Voting',
    'attack|encourage_vote': 'Attack & Encourage Voting',
    'policy|attack': 'Policy & Attack'
}
def readable_name(var):
    if var.startswith('C(content_cat)'):
        key = var.split('T.')[1].rstrip(']')
        return readable_cat.get(key, key.replace('|', ' & ').title())
    mapping = {
        'sentiment_score': 'Sentiment Score',
        'tweet_length': 'Tweet Length (chars)',
        'num_hashtags': 'Number of Hashtags',
        'num_mentions': 'Number of Mentions',
        'hour_of_day': 'Posting Hour'
    }
    return mapping.get(var, var)

#plots/figures

# Distribution of Log-Engagement
plt.figure()
plt.hist(df['log_engagement'], bins=50, color='skyblue', edgecolor='gray')
plt.xlabel('Log(Engagement + 1)')
plt.ylabel('Frequency')
plt.title('Distribution of Engagement (Log Scale)')
plt.tight_layout()
plt.show()

# Monthly Trends in Sentiment & Engagement
monthly = df.groupby('year_month').agg({'sentiment_score':'mean', 'engagement':'mean'}).reset_index()
fig, ax1 = plt.subplots()
ax1.plot(monthly['year_month'], monthly['sentiment_score'], marker='o', color='blue')
ax1.set_xlabel('Month')
ax1.set_ylabel('Average Sentiment', color='blue')
ax2 = ax1.twinx()
ax2.plot(monthly['year_month'], monthly['engagement'], marker='x', color='green')
ax2.set_ylabel('Average Engagement', color='green')
plt.title('Monthly Trends in Sentiment & Engagement')
fig.autofmt_xdate()
plt.tight_layout()
plt.show()

# Engagement by Content Type
plt.figure(figsize=(10,5))
cats = df['content_cat'].cat.categories
data_by_cat = [df[df['content_cat']==c]['log_engagement'] for c in cats]
labels = [readable_cat.get(c, c.replace('|', ' & ').title()) for c in cats]
plt.boxplot(data_by_cat, tick_labels=labels, showfliers=False)
plt.xticks(rotation=45, ha='right')
plt.ylabel('Log(Engagement + 1)')
plt.title('Engagement by Content Type')
plt.tight_layout()
plt.show()

# OLS Regression Coefficients
coefs = ols_mod.params.drop('Intercept')
errs = ols_mod.bse.drop('Intercept')
vars_ = [readable_name(v) for v in coefs.index]
y = np.arange(len(coefs))
plt.figure(figsize=(8, len(coefs)*0.5))
plt.errorbar(coefs, y, xerr=1.96*errs, fmt='o', color='black')
plt.yticks(y, vars_)
plt.axvline(0, color='gray', linewidth=1)
plt.xlabel('Coefficient (95% CI)')
plt.title('OLS Regression Coefficients')
plt.tight_layout()
plt.show()

# Negative-Binomial Model IRRs
pcoefs = pois_mod.params.drop('Intercept')
pci = pois_mod.conf_int().drop('Intercept')
exp_coef = np.exp(pcoefs)
exp_low = np.exp(pci[0])
exp_high = np.exp(pci[1])
vars_p = [readable_name(v) for v in pcoefs.index]
y2 = np.arange(len(exp_coef))
plt.figure(figsize=(8, len(exp_coef)*0.5))
plt.errorbar(exp_coef, y2, xerr=[exp_coef-exp_low, exp_high-exp_coef], fmt='o', color='darkred')
plt.yticks(y2, vars_p)
plt.axvline(1, color='gray', linewidth=1)
plt.xlabel('Incident Rate Ratio (95% CI)')
plt.title('Negative-Binomial Model IRRs')
plt.tight_layout()
plt.show()

#Baseline Engagement by Politician
ri = mixed_mod.random_effects
ints = {}
for pol, eff in ri.items():
    if isinstance(eff, dict):
        val = list(eff.values())[0]
    else:
        val = eff.iloc[0] if hasattr(eff, 'iloc') else eff[0]
    ints[pol] = val
ints_series = pd.Series(ints).sort_values()
plt.figure(figsize=(8, 4))
ints_series.plot.barh(color='teal')
plt.xlabel('Random Intercept (Log Scale)')
plt.ylabel('Politician')
plt.title('Baseline Engagement by Politician')
plt.tight_layout()
plt.show()

print("figures generated ")

import os
import json
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.regression.mixed_linear_model import MixedLM

# file upload
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    BASE_DIR = '/content/drive/MyDrive'
except ImportError:
    BASE_DIR = '.'

def find_json(names):
    for d in [BASE_DIR, '/content', '/mnt/data', '.']:
        for n in names:
            p = os.path.join(d, n)
            if os.path.exists(p): return p
    raise FileNotFoundError(f"None of {names} found in expected dirs")

dataset_path = find_json(['dataset.json'])
output_path  = find_json(['output.json'])
print(f"Using dataset: {dataset_path}\nUsing output: {output_path}\n")

# json loader
def load_json(path):
    txt = open(path, 'r', encoding='utf-8').read()
    txt = re.sub(r',\s*([\]\}])', r'\1', txt)
    try:
        obj = json.loads(txt)
        if isinstance(obj, list): return obj
        if isinstance(obj, dict):
            for v in obj.values():
                if isinstance(v, list): return v
            return [obj]
    except:
        pass
    recs = []
    for line in txt.splitlines():
        entry = line.strip().rstrip(',')
        if entry.startswith('{'):
            try: recs.append(json.loads(entry))
            except: pass
    return recs

# load and merge
df_raw  = pd.DataFrame(load_json(dataset_path))
df_sent = pd.DataFrame(load_json(output_path))
df      = pd.merge(df_raw, df_sent, left_on='Text', right_on='text', how='inner')
print(f"Merged {len(df)} tweets\n")

#preprocessing
for c in ['Replies','Reposts','Likes']:
    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

df['engagement'] = df[['Replies','Reposts','Likes']].sum(axis=1)

df['Time'] = pd.to_datetime(df['Time'], errors='coerce')

df['year_month'] = df['Time'].dt.to_period('M').dt.to_timestamp()

if 'confidence_scores' in df.columns:
    df['sentiment_score'] = df['confidence_scores'].apply(
        lambda x: x.get('positive',0) - x.get('negative',0)
    )
else:
    df['sentiment_score'] = 0.0

#content flags
flags = {
    'has_image':      r'https?://\S+\.(jpg|png|gif)',
    'has_video':      r'https?://\S+\.(mp4|gif)',
    'policy':         r'health care|economy|education|tax|immigration|environment|infrastructure',
    'attack':         r'my opponent|they|crooked|failure|incompetent|radical',
    'encourage_vote': r'vote|voting|election|ballot|turn out'
}

for name, pat in flags.items():
    df[name] = df['Text'].str.contains(pat, flags=re.IGNORECASE, na=False)

# Table/Datya
print("---=--- Descriptive Statistics -----")
# Engagement summary
eng_sum = df['engagement'].describe()
print("Engagement (replies + reposts + likes):")
print(eng_sum[['count','mean','std','min','50%','max']].to_string(), "\n")
# Sentiment summary
sent_sum = df['sentiment_score'].describe()
print("Sentiment Score:")
print(sent_sum[['count','mean','std','min','50%','max']].to_string(), "\n")
# Content categories
df['content_cat'] = df.apply(
    lambda r: '|'.join([k for k in flags if r[k]]) or 'none', axis=1
).astype('category')
print("Content Category Counts:")
print(df['content_cat'].value_counts().to_string(), "\n")

#fature engineering
print("----- Feature Summaries ---")
df['log_engagement'] = np.log1p(df['engagement'])
df['tweet_length']   = df['Text'].str.len()
df['num_hashtags']   = df['Text'].str.count(r'#\w+')
df['num_mentions']   = df['Text'].str.count(r'@\w+')
df['hour_of_day']    = df['Time'].dt.hour
print(df[['log_engagement','tweet_length','num_hashtags','num_mentions','hour_of_day']] \
      .describe().to_string(), "\n")

#model fitting
print("---------- Model Summaries -------")
formula = 'log_engagement ~ sentiment_score + C(content_cat) + tweet_length + num_hashtags + num_mentions + hour_of_day'
ols_mod  = smf.ols(formula, data=df).fit()
print("OLS Regression Results:\n", ols_mod.summary(), "\n")
pois_mod = smf.glm(
    'engagement ~ sentiment_score + C(content_cat) + tweet_length + num_hashtags + num_mentions + hour_of_day',
    data=df, family=sm.families.NegativeBinomial()
).fit()
print("Negative-Binomial GLM Results:\n", pois_mod.summary(), "\n")
mixed_mod = MixedLM.from_formula(formula, groups='politician', data=df).fit(reml=False)
print("Mixed-Effects Model Results:\n", mixed_mod.summary(), "\n")